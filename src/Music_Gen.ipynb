{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import metrics\n",
    "\n",
    "import random # for random\n",
    "import sys # for printing\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable for the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_idx = {}\n",
    "idx_to_char = {}\n",
    "index = 0\n",
    "\n",
    "bufferText = ''\n",
    "inputSeq = []\n",
    "ouputSeq = []\n",
    "inputSeqIdx = []\n",
    "outputSeqIdx = []\n",
    "inputSeqOH = []\n",
    "outputSeqOH = []\n",
    "\n",
    "sequenceLen = 20\n",
    "sequenceShift = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all abc files in folder\n",
    "for filePath in Path('../data/processed').glob('*.abc'):\n",
    "    # check if file\n",
    "    if filePath.is_file():\n",
    "        # open file and read all char\n",
    "        with filePath.open('r') as abc:\n",
    "            for line in abc:\n",
    "                # read all char\n",
    "                for c in line:\n",
    "                    # check if exist\n",
    "                    if c not in char_to_idx:\n",
    "                        char_to_idx[c] = index\n",
    "                        idx_to_char[index] = c\n",
    "                        # increment\n",
    "                        index += 1\n",
    "                # add to bufferText\n",
    "                bufferText += line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98101 98101\n"
     ]
    }
   ],
   "source": [
    "# extract inputSeq and outputSeq\n",
    "for i in range(int(len(bufferText) - sequenceLen)):\n",
    "    tempNum = i\n",
    "    inputSeq.append(bufferText[tempNum: tempNum + sequenceLen])\n",
    "    ouputSeq.append(bufferText[tempNum + 1: tempNum + sequenceLen + 1])\n",
    "print(len(inputSeq),len(ouputSeq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to index\n",
    "for i in range(len(inputSeq)):\n",
    "    tmpInput = []\n",
    "    tmpOutput = []\n",
    "    for c in inputSeq[i]:\n",
    "        tmpInput.append(char_to_idx[c])\n",
    "    for c in ouputSeq[i]:\n",
    "        tmpOutput.append(char_to_idx[c])\n",
    "    # append \n",
    "    inputSeqIdx.append(tmpInput)\n",
    "    outputSeqIdx.append(tmpOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98101, 20, 52) (98101, 20, 52)\n"
     ]
    }
   ],
   "source": [
    "# convert to one hot \n",
    "inputSeqOH = to_categorical(inputSeqIdx, num_classes=len(char_to_idx))\n",
    "outputSeqOH = to_categorical(outputSeqIdx, num_classes=len(char_to_idx))\n",
    "\n",
    "print(inputSeqOH.shape, outputSeqOH.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instruction\n",
    "- We want two LSTM cells of dimension 512, with the second LSTM cell taking as input the output of the first cell. We want both cells to output sequences (i.e. we're interested in output at every timestep and not just at the end).\n",
    "- Add Dropout with keep probability 80% for the LSTM cells.\n",
    "- Add a dense layer of dimension size equal to the number of unique characters in your text. This layer converts the LSTM output of dimension 512 into the odds that the output should be each character (e.g. 'c' or 'k')\n",
    "- Apply softmax to the dense layer to convert the values into probabilities the output should be each character.\n",
    "- Calculate categorical cross entropy loss between the predicted softmax probabilities and labels.\n",
    "- Apply an optimizer e.g. RMSProp with an appropriate learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model constant\n",
    "'''\n",
    "KEEP_PROB = 0.8\n",
    "DROPOUT = 1 - KEEP_PROB\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dense -> Just your regular densely-connected NN layer.\n",
    "Dense(value) -> output will be of value dimension\n",
    "\n",
    "* have to add return_sequences=True, https://github.com/keras-team/keras/issues/7403\n",
    "'''\n",
    "\n",
    "# building model\n",
    "model = Sequential()\n",
    "# one cell\n",
    "model.add(LSTM(512, input_shape=(sequenceLen, len(char_to_idx)), dropout=(DROPOUT), return_sequences=True))\n",
    "#model.add(Dense(len(char_to_idx))) # output as length of char_to_idx, which is 71\n",
    "#model.add(Activation('softmax'))\n",
    "# second cell\n",
    "model.add(LSTM(512, input_shape=(sequenceLen, len(char_to_idx)), dropout=(DROPOUT), return_sequences=True)) # input from previous dense layer\n",
    "model.add(Dense(len(char_to_idx)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# optimizer\n",
    "optimizer = RMSprop(lr=LEARNING_RATE)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "98101/98101 [==============================] - 2965s 30ms/step - loss: 0.7293 - acc: 0.7452\n",
      "Epoch 2/2\n",
      "98101/98101 [==============================] - 1123s 11ms/step - loss: 0.6936 - acc: 0.7569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14516ae48>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "model.fit(inputSeqOH, outputSeqOH,\n",
    "          batch_size=128,\n",
    "          epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sequence of characters note\n",
    "def generate_seq(model, mapping, seq_length, seed_note, n_chars):\n",
    "    nprobs = 3\n",
    "    in_text = seed_note\n",
    "    # generate a fixed number of characters\n",
    "    for _ in range(n_chars):\n",
    "        # encode the characters as integers\n",
    "        encoded = [mapping[char] for char in in_text]\n",
    "        # truncate sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "        # one hot encode\n",
    "        encoded = to_categorical(encoded, num_classes=len(mapping))\n",
    "        \n",
    "        # get prediction\n",
    "        #y_hat = model.predict_classes(encoded)\n",
    "        # convert to char (1, 20, 53)\n",
    "        #in_text += idx_to_char[y_hat[0][-1]]\n",
    "        \n",
    "        # weighted sampling method\n",
    "        yhat = model.predict(encoded)\n",
    "        x = yhat[0][-1]\n",
    "        x_copy = x.copy()\n",
    "        x_ten_sorted = sorted(x, reverse=True)[:nprobs]\n",
    "        x_chosen = random.choices(x_ten_sorted, weights=x_ten_sorted, k=1)\n",
    "        x_index = np.where(x_copy == x_chosen)\n",
    "        in_text += idx_to_char[x_index[0][0]]\n",
    "        \n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFF|D3 ||\n",
      "\n",
      "\n",
      "D|\"G\"G2G \"D7\"AGF|\"G\"G3 -G2::\n",
      "B/2c/2|\"G\"d2g gfg|\"C\"e2g \"G7\"fgf|\"C\"e3 \"D7\"d2c|\"G\"B2B BAB|\"C\"c3 c2:|\n",
      "\n",
      "\n",
      "|:E|\"A\"E2E EAB|\"Am\"c2A A^GA|\"D7\"def \"G\"gdB|\"D7\"cAF \"G\"G2:|\n",
      "\n",
      "\n",
      "D|\"G\"DGB dBG|\"D7\"FGA DEF|\"G\"G3 -G2::\n",
      "B/2c/2|\"G\"d2d dBc|\"G\"dge \"D7\"d2c|\"G\"BAG G2:|\n",
      "|:B/2c/2|\"G\"d^cd \"Em\"edB|\"D\"def \"C\"gfe|\"G\"ded \"D7\"e2f|\"G\"g3 \"Em\"gfg|\"D\"afd \"A7\"gec|\"Bm\"dff \"E7/g+\"efg|\\\n",
      "\"A\"a3 ||\n",
      "\n",
      "\n",
      "|E|\"D\"F3 \"A7/e\"FED|\n",
      "FFF|D3 ||\n",
      "D|\"G\"G2G \"D7\"AGF|\"G\"G3 -G2::\n",
      "B/2c/2|\"G\"d2g gfg|\"C\"e2g \"G7\"fgf|\"C\"e3 \"D7\"d2c|\"G\"B2B BAB|\"C\"c3 c2:|\n",
      "|:E|\"A\"E2E EAB|\"Am\"c2A A^GA|\"D7\"def \"G\"gdB|\"D7\"cAF \"G\"G2:|\n",
      "D|\"G\"DGB dBG|\"D7\"FGA DEF|\"G\"G3 -G2::\n",
      "B/2c/2|\"G\"d2d dBc|\"G\"dge \"D7\"d2c|\"G\"BAG G2:|\n",
      "|:B/2c/2|\"G\"d^cd \"Em\"edB|\"D\"def \"C\"gfe|\"G\"ded \"D7\"e2f|\"G\"g3 \"Em\"gfg|\"D\"afd \"A7\"gec|\"Bm\"dff \"E7/g+\"efg|\\\n",
      "\"A\"a3 ||\n",
      "|E|\"D\"F3 \"A7/e\"FED|\n"
     ]
    }
   ],
   "source": [
    "generatedSeq = generate_seq(model, char_to_idx, sequenceLen, 'FFF|D', 384)\n",
    "print(generatedSeq)\n",
    "\n",
    "# manually strip away double \\n\\n\n",
    "strippedGeneratedSeq = generatedSeq.replace('\\n\\n', '')\n",
    "print(strippedGeneratedSeq)\n",
    "\n",
    "# append to template\n",
    "TEMPLATE = '''\n",
    "X: 1\n",
    "T: custom generated\n",
    "S:Trad\n",
    "L:1/8\n",
    "M:6/8\n",
    "K:C\n",
    "{}\n",
    "\n",
    "'''\n",
    "with open('../output/abc/generated_abc.abc','w') as f:\n",
    "    f.write(TEMPLATE.format(strippedGeneratedSeq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C 8\n",
      "[['f4', 8.0], ['f4', 8.0], ['f4', 8.0], ['d4*', 2.6666666666666665], ['d4', 8.0], ['g4*', 4.0], ['g4', 8.0], ['a4', 8.0], ['g4', 8.0], ['f4', 8.0], ['g4*', 2.6666666666666665], ['g4', 4.0], ['f4', 8.0], ['f4', 8.0], ['f4', 8.0], ['d4*', 2.6666666666666665], ['d4', 8.0], ['g4*', 4.0], ['g4', 8.0], ['a4', 8.0], ['g4', 8.0], ['f4', 8.0], ['g4*', 2.6666666666666665], ['g4', 4.0], ['b4', 4.0], ['c5', 4.0], ['d5*', 4.0], ['g5', 8.0], ['g5', 8.0], ['f5', 8.0], ['g5', 8.0], ['e5*', 4.0], ['g5', 8.0], ['f5', 8.0], ['g5', 8.0], ['f5', 8.0], ['e5*', 2.6666666666666665], ['d5', 4.0], ['c5', 8.0], ['b4*', 4.0], ['b4', 8.0], ['b4', 8.0], ['a4', 8.0], ['b4', 8.0], ['c5*', 2.6666666666666665], ['c5', 4.0], ['b4', 4.0], ['c5', 4.0], ['d5*', 4.0], ['g5', 8.0], ['g5', 8.0], ['f5', 8.0], ['g5', 8.0], ['e5*', 4.0], ['g5', 8.0], ['f5', 8.0], ['g5', 8.0], ['f5', 8.0], ['e5*', 2.6666666666666665], ['d5', 4.0], ['c5', 8.0], ['b4*', 4.0], ['b4', 8.0], ['b4', 8.0], ['a4', 8.0], ['b4', 8.0], ['c5*', 2.6666666666666665], ['c5', 4.0], ['e4*', 8.0], ['e4*', 4.0], ['e4', 8.0], ['e4', 8.0], ['a4', 8.0], ['b4', 8.0], ['c5*', 4.0], ['a4', 8.0], ['a4', 8.0], ['g#4', 8.0], ['a4', 8.0], ['d5*', 8.0], ['e5', 8.0], ['f5', 8.0], ['g5', 8.0], ['d5', 8.0], ['b4', 8.0], ['c5*', 8.0], ['a4', 8.0], ['f4', 8.0], ['g4', 4.0], ['e4*', 8.0], ['e4*', 4.0], ['e4', 8.0], ['e4', 8.0], ['a4', 8.0], ['b4', 8.0], ['c5*', 4.0], ['a4', 8.0], ['a4', 8.0], ['g#4', 8.0], ['a4', 8.0], ['d5*', 8.0], ['e5', 8.0], ['f5', 8.0], ['g5', 8.0], ['d5', 8.0], ['b4', 8.0], ['c5*', 8.0], ['a4', 8.0], ['f4', 8.0], ['g4', 4.0], ['d4', 8.0], ['d4*', 8.0], ['g4', 8.0], ['b4', 8.0], ['d5', 8.0], ['b4', 8.0], ['g4', 8.0], ['f4*', 8.0], ['g4', 8.0], ['a4', 8.0], ['d4', 8.0], ['e4', 8.0], ['f4', 8.0], ['g4*', 2.6666666666666665], ['g4', 4.0], ['d4', 8.0], ['d4*', 8.0], ['g4', 8.0], ['b4', 8.0], ['d5', 8.0], ['b4', 8.0], ['g4', 8.0], ['f4*', 8.0], ['g4', 8.0], ['a4', 8.0], ['d4', 8.0], ['e4', 8.0], ['f4', 8.0], ['g4*', 2.6666666666666665], ['g4', 4.0], ['b4', 4.0], ['c5', 4.0], ['d5*', 4.0], ['d5', 8.0], ['d5', 8.0], ['b4', 8.0], ['c5', 8.0], ['d5*', 8.0], ['g5', 8.0], ['e5', 8.0], ['d5', 4.0], ['c5', 8.0], ['b4*', 8.0], ['a4', 8.0], ['g4', 8.0], ['g4', 4.0], ['b4', 4.0], ['c5', 4.0], ['d5*', 4.0], ['d5', 8.0], ['d5', 8.0], ['b4', 8.0], ['c5', 8.0], ['d5*', 8.0], ['g5', 8.0], ['e5', 8.0], ['d5', 4.0], ['c5', 8.0], ['b4*', 8.0], ['a4', 8.0], ['g4', 8.0], ['g4', 4.0], ['b4*', 4.0], ['c5', 4.0], ['d5*', 8.0], ['c#5', 8.0], ['d5', 8.0], ['e5', 8.0], ['d5', 8.0], ['b4', 8.0], ['d5*', 8.0], ['e5', 8.0], ['f5', 8.0], ['g5', 8.0], ['f5', 8.0], ['e5', 8.0], ['d5*', 8.0], ['e5', 8.0], ['d5', 8.0], ['e5', 4.0], ['f5', 8.0], ['g5*', 2.6666666666666665], ['g5', 8.0], ['f5', 8.0], ['g5', 8.0], ['a5*', 8.0], ['f5', 8.0], ['d5', 8.0], ['g5', 8.0], ['e5', 8.0], ['c5', 8.0], ['d5*', 8.0], ['f5', 8.0], ['f5', 8.0], ['e5', 8.0], ['f5', 8.0], ['g5', 8.0], ['a5', 2.6666666666666665], ['e4*', 8.0], ['f4*', 2.6666666666666665], ['f4', 8.0], ['e4', 8.0], ['d4', 8.0], ['b4*', 4.0], ['c5', 4.0], ['d5*', 8.0], ['c#5', 8.0], ['d5', 8.0], ['e5', 8.0], ['d5', 8.0], ['b4', 8.0], ['d5*', 8.0], ['e5', 8.0], ['f5', 8.0], ['g5', 8.0], ['f5', 8.0], ['e5', 8.0], ['d5*', 8.0], ['e5', 8.0], ['d5', 8.0], ['e5', 4.0], ['f5', 8.0], ['g5*', 2.6666666666666665], ['g5', 8.0], ['f5', 8.0], ['g5', 8.0], ['a5*', 8.0], ['f5', 8.0], ['d5', 8.0], ['g5', 8.0], ['e5', 8.0], ['c5', 8.0], ['d5*', 8.0], ['f5', 8.0], ['f5', 8.0], ['e5', 8.0], ['f5', 8.0], ['g5', 8.0], ['a5', 2.6666666666666665], ['e4*', 8.0], ['f4*', 2.6666666666666665], ['f4', 8.0], ['e4', 8.0], ['d4', 8.0]]\n",
      "\n",
      "254\n",
      "Writing to file out.wav\n",
      "[1/254]\t\n",
      "[5/254]\t\n",
      "[9/254]\t\n",
      "[13/254]\t\n",
      "[17/254]\t\n",
      "[21/254]\t\n",
      "[25/254]\t\n",
      "[29/254]\t\n",
      "[33/254]\t\n",
      "[37/254]\t\n",
      "[41/254]\t\n",
      "[45/254]\t\n",
      "[49/254]\t\n",
      "[53/254]\t\n",
      "[57/254]\t\n",
      "[61/254]\t\n",
      "[65/254]\t\n",
      "[69/254]\t\n",
      "[73/254]\t\n",
      "[77/254]\t\n",
      "[81/254]\t\n",
      "[85/254]\t\n",
      "[89/254]\t\n",
      "[93/254]\t\n",
      "[97/254]\t\n",
      "[101/254]\t\n",
      "[105/254]\t\n",
      "[109/254]\t\n",
      "[113/254]\t\n",
      "[117/254]\t\n",
      "[121/254]\t\n",
      "[125/254]\t\n",
      "[129/254]\t\n",
      "[133/254]\t\n",
      "[137/254]\t\n",
      "[141/254]\t\n",
      "[145/254]\t\n",
      "[149/254]\t\n",
      "[153/254]\t\n",
      "[157/254]\t\n",
      "[161/254]\t\n",
      "[165/254]\t\n",
      "[169/254]\t\n",
      "[173/254]\t\n",
      "[177/254]\t\n",
      "[181/254]\t\n",
      "[185/254]\t\n",
      "[189/254]\t\n",
      "[193/254]\t\n",
      "[197/254]\t\n",
      "[201/254]\t\n",
      "[205/254]\t\n",
      "[209/254]\t\n",
      "[213/254]\t\n",
      "[217/254]\t\n",
      "[221/254]\t\n",
      "[225/254]\t\n",
      "[229/254]\t\n",
      "[233/254]\t\n",
      "[237/254]\t\n",
      "[241/254]\t\n",
      "[245/254]\t\n",
      "[249/254]\t\n",
      "[253/254]\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# it does not work as the current directory is diff from jupyter notebook relative path\n",
    "import subprocess\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "subprocess.call(\"read_abc.py ../abc/generated_abc.abc\")\n",
    "'''\n",
    "import os\n",
    "# generate out.wav\n",
    "%run -i PySynth/read_abc.py \"../output/abc/generated_abc.abc\"\n",
    "# move out.wav to ../wav \n",
    "os.rename(\"out.wav\", \"../output/wav/generated.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "\n",
    "#model.save('../model/2ep_jigs_nodense.h5')\n",
    "#dump(char_to_idx, open('../model/2ep_jigs_nodense_c2i.pkl', 'wb'))\n",
    "#dump(idx_to_char, open('../model/2ep_jigs_nodense_i2c.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/AIAP/wrap-up/RNN/src/PySynth/read_abc.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpickle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# loading model, pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#model = load_model('../model/4ep_jigs.h5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#char_to_idx = load(open('../model/4ep_jigs_c2i.pkl', 'rb'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.model'"
     ]
    }
   ],
   "source": [
    "from pickle import load\n",
    "from keras.models import load_model\n",
    "# loading model, pickle\n",
    "#model = load_model('../model/4ep_jigs.h5')\n",
    "#char_to_idx = load(open('../model/4ep_jigs_c2i.pkl', 'rb'))\n",
    "#idx_to_char = load(open('../model/4ep_jigs_i2c.pkl', 'rb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
